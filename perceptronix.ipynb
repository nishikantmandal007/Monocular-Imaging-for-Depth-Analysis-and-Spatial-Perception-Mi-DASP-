{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "wwjmkkD1xCiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "id": "pPzIvrmuyZ9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "vVWs34WrvJSA",
        "outputId": "5aa14ac0-421f-4c30-933d-0c7f1fdc90f0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8b5ddcd440bc>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#Including the vision depth class from the visiondistance007 which will calculate distnace between the objects with reference to camera\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mvisdept\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvision_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Load a MiDas model for depth estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/vision_distance.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Loading Mask RCNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         self.net = cv2.dnn.readNetFromTensorflow(\"MODEL/visdepth/frozen_inference_graph_coco.pb\",\n\u001b[0m\u001b[1;32m     11\u001b[0m                                             \"MODEL/visdepth/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\")\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetPreferableBackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDNN_BACKEND_CUDA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/dnn/src/caffe/caffe_io.cpp:1138: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"MODEL/visdepth/frozen_inference_graph_coco.pb\" in function 'ReadProtoFromBinaryFile'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from vision_distance import vision_depth\n",
        "\n",
        "#from vision_distance007 import *\n",
        "\n",
        "#Including the vision depth class from the visiondistance007 which will calculate distnace between the objects with reference to camera\n",
        "visdept= vision_depth()\n",
        "\n",
        "# Load a MiDas model for depth estimation\n",
        "#model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
        "#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
        "model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
        "\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
        "\n",
        "# Move model to GPU if available\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()\n",
        "\n",
        "# Load transforms to resize and normalize the image\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "\n",
        "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
        "    transform = midas_transforms.dpt_transform\n",
        "else:\n",
        "    transform = midas_transforms.small_transform\n",
        "\n",
        "\n",
        "# Open up the video capture from a webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while cap.isOpened():\n",
        "\n",
        "    success, img = cap.read()\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Apply input transforms\n",
        "    input_batch = transform(img).to(device)\n",
        "\n",
        "    # Prediction and resize to original resolution\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_batch)\n",
        "\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=img.shape[:2],\n",
        "            mode=\"bicubic\",\n",
        "            align_corners=False,\n",
        "        ).squeeze()\n",
        "\n",
        "    depth_map = prediction.cpu().numpy()\n",
        "\n",
        "    depth_map = cv2.normalize(depth_map, None, 0, 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_64F)\n",
        "\n",
        "\n",
        "    end = time.time()\n",
        "    totalTime = end - start\n",
        "\n",
        "    fps = 1 / totalTime\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    depth_map = (depth_map*255).astype(np.uint8)\n",
        "    depth_map = cv2.applyColorMap(depth_map , cv2.COLORMAP_MAGMA)\n",
        "    img = visdept.draw_object_mask(img)\n",
        "    boxes, classes, contours, centers = visdept.detect_objects_mask(img)\n",
        "    visdept.draw_object_info(img, depth_map)\n",
        "\n",
        "\n",
        "    cv2.putText(img, f'FPS: {int(fps)}', (20,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
        "    cv2.imshow('Image', img)\n",
        "    cv2.imshow('Depth Map', depth_map)\n",
        "\n",
        "\n",
        "    if cv2.waitKey(5) & 0xFF == 27:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}